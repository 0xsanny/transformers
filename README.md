# Transformers
A collection of resources to study Transformers in depth. 

## The original paper

- [Attention Is All You Need](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)


## Paper Reviews
- [AISC Transformer Overview](https://www.youtube.com/watch?time_continue=2175&v=S0KakHcj_rs)
- [Yannic Kilcher](https://www.youtube.com/watch?v=iDulhoQ2pro)
- [Microsoft Reading Group](https://www.youtube.com/watch?v=y96jfSz2IHY&t=2392s)
- [Kaggle Reading Group](https://www.youtube.com/watch?v=54uLU7Nxyv8&t=2182s)


## Blog Posts
- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)
- [Peter Bloem](http://www.peterbloem.nl/blog/transformers)
- [Lilian Weng](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)


## Lectures and Talks
- [fastai Introduction to Transformers](https://www.youtube.com/watch?v=AFkGPmU16QA)
- [Stanford CS224u](https://www.youtube.com/watch?v=lzBB7xoZ3Q8&t=746s)
- [Stanford CS224n](https://www.youtube.com/watch?v=5vcj8kSwBCY&t=1211s)
- [Lukasz Kaiser's Talk](https://www.youtube.com/watch?v=rBCqOTEfxvg&t=1075s)



## Code Walkthroughs 
- [AISC Video Recording of Code Review in PyTorch](https://www.youtube.com/watch?v=KMY2Knr4iAs)
- [Transformers in TensorFlow 2.0](https://www.tensorflow.org/beta/tutorials/text/transformer)



## Follow-Up Papers
- [TransformerXL](https://arxiv.org/abs/1901.02860)
- [Evolved Transformer](https://arxiv.org/abs/1901.11117)
- [Image Transformer](https://arxiv.org/abs/1802.05751)
- [Music Transformer](https://arxiv.org/abs/1809.04281)
- [TTS Transformer](https://arxiv.org/abs/1809.08895)
- [Sparse Transformer](https://arxiv.org/abs/1904.10509)
- [Levenshtein Transformer](https://arxiv.org/abs/1905.11006)
- [BERT](https://arxiv.org/abs/1810.04805)
- [UniLM](https://arxiv.org/abs/1905.03197)
- [XLNet](https://arxiv.org/abs/1906.08237)
- [MASS](https://arxiv.org/abs/1905.02450)
- [Adapative Attention Spans](https://arxiv.org/abs/1905.07799)
- [All Attention Layers](https://arxiv.org/abs/1907.01470)
- [Large Memory Layers with Product Keys](https://arxiv.org/abs/1907.05242)


